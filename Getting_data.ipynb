{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "94bebbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from dateutil.parser import parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "680c1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_domain(email_address: str) -> str:\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "\n",
    "assert get_domain('joelgrus@gmail.com') == 'gmail.com'\n",
    "assert get_domain('joel@m.datasciencester.com') == 'm.datasciencester.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a14aa866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gmail.com': 4, 'ukr.net': 3, 'yahoo.com': 2, 'mail.com': 1})\n"
     ]
    }
   ],
   "source": [
    "with open('data/emails.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if '@' in line)\n",
    "\n",
    "print(domain_counts)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "375f40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tab_delimited_stock_prices.txt', 'w') as f:\n",
    "    f.write(\"\"\"6/20/2014\\tAAPL\\t90.91\n",
    "6/20/2014\\tMSFT\\t41.68\n",
    "6/20/2014\\tFB\\t64.5\n",
    "6/19/2014\\tAAPL\\t91.86\n",
    "6/19/2014\\tMSFT\\t41.51\n",
    "6/19/2014\\tFB\\t64.34\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fba68e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/20/2014 AAPL 90.91\n",
      "6/20/2014 MSFT 41.68\n",
      "6/20/2014 FB 64.5\n",
      "6/19/2014 AAPL 91.86\n",
      "6/19/2014 MSFT 41.51\n",
      "6/19/2014 FB 64.34\n"
     ]
    }
   ],
   "source": [
    "with open('data/tab_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter='\\t')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        print(date, symbol, closing_price)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac34a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "015ab4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/tab_delimited_stock_prices.txt', 'a', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    today = datetime.today()\n",
    "    today = today.strftime(\"%#m/%#d/%Y\")\n",
    "    for stock, price in todays_prices.items():\n",
    "        writer.writerow([today, stock, price])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a85a77",
   "metadata": {},
   "source": [
    "# HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1c7fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = (\"https://raw.githubusercontent.com/\"\n",
    "       \"joelgrus/data/master/getting-data.html\")\n",
    "\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb18c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en-US\"><head>\n",
       "    <title>Getting Data</title>\n",
       "    <meta charset=\"utf-8\"/>\n",
       "</head>\n",
       "<body>\n",
       "    <h1>Getting Data</h1>\n",
       "    <div class=\"explanation\">\n",
       "        This is an explanation.\n",
       "    </div>\n",
       "    <div class=\"comment\">\n",
       "        This is a comment.\n",
       "    </div>\n",
       "    <div class=\"content\">\n",
       "        <p id=\"p1\">This is the first paragraph.</p>\n",
       "        <p class=\"important\">This is the second paragraph.</p>\n",
       "    </div>\n",
       "    <div class=\"signature\">\n",
       "        <span id=\"name\">Joel</span>\n",
       "        <span id=\"twitter\">@joelgrus</span>\n",
       "        <span id=\"email\">joelgrus-at-gmail</span>\n",
       "    </div>\n",
       "\n",
       "\n",
       "</body></html>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73e90401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<p id=\"p1\">This is the first paragraph.</p>,\n",
       " 'This is the first paragraph.',\n",
       " ['This', 'is', 'the', 'first', 'paragraph.'],\n",
       " 'p1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_paragraph = soup.find('p')\n",
    "first_paragraph_text = soup.p.text\n",
    "first_paragraph_word = soup.p.text.split()\n",
    "first_paragraph_id = soup.p.get('id')\n",
    "first_paragraph, first_paragraph_text, first_paragraph_word, first_paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d517e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<p id=\"p1\">This is the first paragraph.</p>,\n",
       "  <p class=\"important\">This is the second paragraph.</p>],\n",
       " [<p id=\"p1\">This is the first paragraph.</p>])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paragraphs = soup.find_all('p')\n",
    "paragraph_with_ids = [p for p in soup('p') if p.get('id')]\n",
    "all_paragraphs, paragraph_with_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dfc125e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<p class=\"important\">This is the second paragraph.</p>],\n",
       " [<p class=\"important\">This is the second paragraph.</p>],\n",
       " [<p class=\"important\">This is the second paragraph.</p>])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impotant_paragraphs = soup('p', {'class': 'important'})\n",
    "impotant_paragraphs2 = soup('p', 'important')\n",
    "impotant_paragraphs3 = [p for p in soup('p') if 'important' in p.get('class', [])]\n",
    "impotant_paragraphs, impotant_paragraphs2, impotant_paragraphs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "095a4e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span id=\"name\">Joel</span>,\n",
       " <span id=\"twitter\">@joelgrus</span>,\n",
       " <span id=\"email\">joelgrus-at-gmail</span>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spans_inside_divs = [span\n",
    "                     for div in soup('div')\n",
    "                     for span in div('span')]\n",
    "spans_inside_divs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a228a61",
   "metadata": {},
   "source": [
    "## House gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9090cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "967\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.house.gov/representatives'\n",
    "text = requests.get(url).text\n",
    "soup = BeautifulSoup(text, 'html5lib')\n",
    "\n",
    "all_urls = [a['href']\n",
    "            for a in soup('a')\n",
    "            if a.has_attr('href')]\n",
    "\n",
    "print(len(all_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e9205a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"^https?://.*\\.house.gov/?$\"\n",
    "\n",
    "assert re.match(regex, \"http://joel.house.gov\")\n",
    "assert re.match(regex, \"https://joel.house.gov\")\n",
    "assert re.match(regex, \"http://joel.house.gov/\")\n",
    "assert re.match(regex, \"https://joel.house.gov/\")\n",
    "assert not re.match(regex, \"joel.house.gov\")\n",
    "assert not re.match(regex, \"http://joel.house.com\")\n",
    "assert not re.match(regex, \"https://joel.house.gov/biography\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1869cb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "876\n"
     ]
    }
   ],
   "source": [
    "good_urls = [url for url in all_urls if re.match(regex, url)]\n",
    "\n",
    "print(len(good_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f84f04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438\n"
     ]
    }
   ],
   "source": [
    "good_urls = list(set(good_urls))\n",
    "\n",
    "print(len(good_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ad36b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get('https://jayapal.house.gov').text\n",
    "soup = BeautifulSoup(html, 'html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2e4510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'https://jayapal.house.gov/category/press-releases/', 'https://jayapal.house.gov/category/news/'}\n"
     ]
    }
   ],
   "source": [
    "links = {a['href'] for a in soup('a') if 'press releases' in a.text.lower()}\n",
    "\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f6f9e",
   "metadata": {},
   "source": [
    "## API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6957a32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_user = 'bohdin'\n",
    "endpoint = f'https://api.github.com/users/{github_user}/repos'\n",
    "\n",
    "repos = json.loads(requests.get(endpoint).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80f9949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [parse(repo[\"created_at\"]) for repo in repos]\n",
    "mounth_counts = Counter(date.month for date in dates)\n",
    "weekday_counts = Counter(date.weekday() for date in dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72de4bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Jupyter Notebook', None, 'HTML', 'Jupyter Notebook', 'Python']\n"
     ]
    }
   ],
   "source": [
    "last_5_repositories = sorted(repos, key=lambda r: r[\"created_at\"], reverse=True)[:5]\n",
    "\n",
    "last_5_repositories = [repo['language'] for repo in last_5_repositories]\n",
    "\n",
    "print(last_5_repositories)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
